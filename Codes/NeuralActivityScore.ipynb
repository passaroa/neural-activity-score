{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for analyzing neural MEA data and generating an objective index - neural activity score - to evaluate network ontogeny and effects of treatments/conditions/perturbation.\n",
    "\n",
    "See Passaro et al. and the README file in the GitHub repository for more information, usage instructions, and sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import shutil\n",
    "import openpyxl as xl\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sys\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Ask which directory to read from, note the following file structure below:\n",
    "# Experiment folder > Plate subfolder(s) > DIV subfolder(s) > Maestro.raw, StatCompiler.csv, etc...\n",
    "# Select the EXPERIMENT folder\n",
    "print('Select experiment folder...')\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "experimentPath = filedialog.askdirectory()\n",
    "print(\"Experiment folder: \",experimentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile .csv StatCompiler files into one .xlsx file ###\n",
    "def compileAndMerge(experimentPath):\n",
    "    # List plate subfolders\n",
    "    plateFolders = os.listdir(experimentPath)\n",
    "\n",
    "    # Loop through each plate folder\n",
    "    for plateFolder in tqdm(plateFolders):\n",
    "        if 'platemap' in plateFolder:\t# Ignore platemap file(s)\n",
    "            continue\n",
    "        else:\n",
    "            platePath = experimentPath + '\\\\' + plateFolder\n",
    "\n",
    "        # Create Compiled plate .xlsx file\n",
    "        fileout = platePath + '\\\\' + '1_AllDaysCompiled_' + plateFolder + '.xlsx'\n",
    "        writer = pd.ExcelWriter(fileout, engine='xlsxwriter')\n",
    "\n",
    "        # Create list of day (DIV) folders within plate folder\n",
    "        divFolders = os.listdir(platePath)\n",
    "\n",
    "        # Go into each DIV folder and list filenames\n",
    "        for div in divFolders:\n",
    "            files = os.listdir(platePath + '\\\\' + div)\n",
    "\n",
    "        # Find .csv files\n",
    "            for filename in files:\n",
    "                if '.csv' in filename and 'Statistics' in filename:\n",
    "                    # Copy file to destination folder\n",
    "                    sourceFile = platePath + '\\\\' + div + '\\\\' + filename\n",
    "                    destinationFile = platePath + '\\\\' + div + '_' + filename\n",
    "                    shutil.copy(sourceFile, destinationFile)\n",
    "\n",
    "                    # Merge file into Compiled .xlsx file\n",
    "                    df = pd.read_csv(sourceFile, names = list(range(0,770)), header=None, engine='python')\n",
    "                    df.to_excel(writer, sheet_name=div, header=False, index=False)\n",
    "        writer.save()\n",
    "        print('Compiled .xlsx file saved for ' + plateFolder + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compileAndMerge(experimentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyze compiled .xslx files for all parameters ###\n",
    "def analyzeStatCompilerFiles(experimentPath):\n",
    "    # List plate subfolders\n",
    "    plateFolders = os.listdir(experimentPath)\n",
    "    plateFolders = [x for x in plateFolders if '.csv' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.raw' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.txt' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.xlsx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.docx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if 'Compiled' not in x]\n",
    "    \n",
    "    # Loop through each plate folder\n",
    "    for plateFolder in plateFolders:\n",
    "        print('Analyzing ' + plateFolder + '...')\n",
    "        if 'platemap' in plateFolder:\t# Ignore platemap file(s)\n",
    "            continue\n",
    "        else:\n",
    "            platePath = experimentPath + '\\\\' + plateFolder\n",
    "\n",
    "        filename = platePath + '\\\\' + '1_AllDaysCompiled_' + plateFolder + '.xlsx'\n",
    "        wb = xl.load_workbook(filename) \t# Load first workbook (one plate compiled, each sheet = 1 day)\n",
    "        sheets = wb.sheetnames\n",
    "\n",
    "        ##### Determine array dimensions (reps, groups, parameters, days) #####\n",
    "        # Define group names\n",
    "        sheet = wb.worksheets[0]    # Use first sheet as template to read from\n",
    "        groups = []                 # Define empty list to store group names\n",
    "        for row in range(1, sheet.max_row+1): # Loop through rows to find row containing Group/Treatment names\n",
    "            if sheet.cell(row = row, column = 1).value == 'Treatment':\n",
    "                groupRow = row\n",
    "                break\n",
    "        for column in range(2,sheet.max_column+1):\n",
    "            if sheet.cell(row = groupRow, column = column).value != None and sheet.cell(row = groupRow, column = column).value not in groups:\n",
    "                groups.append(str(sheet.cell(row = groupRow, column = column).value))\n",
    "        \n",
    "        # Determine number of groups (if not defined in first sheet, try to copy from last sheet first)\n",
    "        numgroups = len(groups)\n",
    "        if numgroups == 0:\n",
    "            lastSheet = wb.worksheets[-1]\n",
    "            for column in range(2,lastSheet.max_column+1):\n",
    "                if lastSheet.cell(row = groupRow, column = column).value != None:\n",
    "                    sheet.cell(row = groupRow, column = column).value = lastSheet.cell(row = groupRow, column = column).value\n",
    "        for column in range(2,sheet.max_column+1):\n",
    "            if sheet.cell(row = groupRow, column = column).value != None and sheet.cell(row = groupRow, column = column).value not in groups:\n",
    "                groups.append(str(sheet.cell(row = groupRow, column = column).value))\n",
    "        \n",
    "        numgroups = len(groups)\n",
    "        if numgroups == 0:\n",
    "            raise Warning(\"Define groups in first sheet of .xlsx file ('Treatment' row) before proceeding.\")\n",
    "            sys.exit()\n",
    "        \n",
    "        # Find number of reps (assumes equal number per group)\n",
    "        for row in range(1, sheet.max_row+1):\n",
    "            if sheet.cell(row = row, column = 1).value == 'Total Wells':\n",
    "                numWells = 0\n",
    "                if sheet.cell(row = row, column = 3).value != None:\n",
    "                    for i in range(2, numgroups+2):\n",
    "                        numWells += int(sheet.cell(row = row, column = i).value)\n",
    "                    break\n",
    "                else:\n",
    "                    numWells = int(sheet.cell(row = row, column = 2).value)\n",
    "\n",
    "        numreps = 0\n",
    "        for group in range(0, len(groups)):\n",
    "            numrepsCounter = 0\n",
    "            for column in range(2,numWells+2):\n",
    "                if str(sheet.cell(row = groupRow, column = column).value) == str(groups[group]):\n",
    "                    numrepsCounter += 1\n",
    "            if numrepsCounter > numreps:\n",
    "                numreps = numrepsCounter\n",
    "\n",
    "        # Count number of calculated parameters\n",
    "        for row in range(1, sheet.max_row+1): # Loop through rows to find row containing first parameter\n",
    "            if sheet.cell(row = row, column = 1).value == 'Number of Spikes':\n",
    "                firstParamRow = row\n",
    "                break\n",
    "        for row in range(1, sheet.max_row+1): # Loop through rows to find row containing last parameter\n",
    "            if sheet.cell(row = row, column = 1).value == 'Synchrony Index':\n",
    "                lastParamRow = row\n",
    "                break        \n",
    "                \n",
    "        numparams = lastParamRow - firstParamRow + 1\n",
    "\n",
    "        # Determine number of days\n",
    "        numdays = len(sheets)\n",
    "\n",
    "        # Create NumPy array with dimensions: reps x groups x parameters x days\n",
    "        array = np.ndarray(shape=(numreps,numgroups,numparams,numdays))\n",
    "\n",
    "        ### Array indices ###\n",
    "        # Reps: 0-x in order of Excel file\n",
    "        # Groups: 0-x in order of Excel file\n",
    "        # Parameters: 0-x = Parameters in order of Excel file from statistics compiler\n",
    "        # Days: 0-x = Days in order of compiled Excel file sheets\n",
    "        #####################\n",
    "\n",
    "        for row in range(1, sheet.max_row+1): # Loop through rows to find row containing Well names\n",
    "            if sheet.cell(row = row, column = 1).value == 'Well':\n",
    "                wellNameRow = row\n",
    "                break\n",
    "        \n",
    "        columns = OrderedDict()    # Create ORDERED dictionary for columns\n",
    "        wells = OrderedDict()      # Create ORDERED dictionary for wells\n",
    "        for i in groups:\n",
    "            columns[i] = []   # Create empty column list for each group\n",
    "            wells[i] = []     # Create empty well list for each group\n",
    "            for column in range(2,numWells+2):\n",
    "                if sheet.cell(row = groupRow, column = column).value == i:    # Fill in column numbers and well names/numbers ('A1, A2', etc.) for each group\n",
    "                    columns[i].append(column)\n",
    "                    wells[i].append(str(sheet.cell(row = wellNameRow, column = column).value))\n",
    "        \n",
    "        ### Fill in array with all values ###\n",
    "        for day in range(0, numdays):    # Loop through sheets (days)\n",
    "            sheet = wb.worksheets[day]\n",
    "            for row in range(1, sheet.max_row+1): # Loop through rows to find row containing first parameter\n",
    "                if sheet.cell(row = row, column = 1).value == 'Number of Spikes':\n",
    "                    firstParamRow = row\n",
    "                    break\n",
    "            for row in range(1, sheet.max_row+1): # Loop through rows to find row containing last parameter\n",
    "                if sheet.cell(row = row, column = 1).value == 'Synchrony Index':\n",
    "                    lastParamRow = row\n",
    "                    break\n",
    "            for param in range(0, numparams):   # Loop through rows (parameters)\n",
    "                row = (param + firstParamRow)\n",
    "                g = 0\n",
    "                for group in columns:\n",
    "                    rep = 0\n",
    "                    for c in columns[group]:\n",
    "                        if sheet.cell(row = row, column = c).value == None:\n",
    "                            array[rep][g][param][day] = 0\n",
    "                        else:\n",
    "                            array[rep][g][param][day] = sheet.cell(row = row, column = c).value\n",
    "                        rep += 1\n",
    "                    g += 1\n",
    "        \n",
    "        # Create empty Pandas dataframe (for later conversion from NumPy array) \n",
    "        data = pd.DataFrame()\n",
    "        df_write = pd.ExcelWriter(platePath + '\\\\' + '2_AnalyzedAllParameters_' + plateFolder + '.xlsx')\n",
    "        for p in tqdm(range(0,numparams)):\n",
    "            paramname = str(sheet.cell(row = (p + firstParamRow), column = 1).value)\n",
    "            xdays = []\n",
    "            sheets_strings = []\n",
    "            for s in sheets:\n",
    "                sheets_strings.append(str(s))\n",
    "            for x in range(0, numdays):\n",
    "                xdays.append(sheets_strings[x][3:6])\n",
    "\n",
    "            ### Slice array for desired parameter and days then convert to pandas dataframe ###\n",
    "            array_sliced = array[:,:,p,:]\n",
    "            array_meshgrid = np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, array_sliced.shape), indexing=\"ij\"))) + [array_sliced.ravel()])\n",
    "\n",
    "            datanew = pd.DataFrame(array_meshgrid, columns = ['Rep', 'Group', 'Day', paramname])   # Convert numpy array to pandas dataframe\n",
    "            \n",
    "            datanew['Rep'] += 1\n",
    "\n",
    "            groupnames = {}\n",
    "            for i in range(0, numgroups):\n",
    "                groupnames[i] = groups[i]\n",
    "            datanew['Group'].replace(groupnames, inplace = True)\n",
    "\n",
    "            daysdict = {}\n",
    "            for i in range(0, numdays):\n",
    "                daysdict[i] = xdays[i]\n",
    "            datanew['Day'].replace(daysdict, inplace = True)\n",
    "\n",
    "            if p == 0:\n",
    "                data['Rep'] = datanew['Rep']\n",
    "                data['Group'] = datanew['Group']\n",
    "                data['Day'] = datanew['Day']\n",
    "            data['Plate'] = plateFolder\n",
    "            data[paramname] = datanew[paramname]\n",
    "            data.to_excel(df_write, \"All Parameters\", index=False)\n",
    "            #print('Analyzed Parameter ',p,'/',numparams)\n",
    "        df_write.save()\n",
    "        print('Analysis Excel file exported for ' + plateFolder + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "analyzeStatCompilerFiles(experimentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergePlateOutputFiles(experimentPath):\n",
    "    plateFolders = os.listdir(experimentPath)\n",
    "    plateFolders = [x for x in plateFolders if '.csv' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.raw' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.txt' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.xlsx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.docx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if 'Compiled' not in x]\n",
    "    \n",
    "    compiledPath = experimentPath + \"\\\\Compiled\"\n",
    "    if not os.path.exists(compiledPath):\n",
    "        os.makedirs(compiledPath)\n",
    "    \n",
    "    # Check if plates are identical\n",
    "    identicalPlates = input(\"Are plates identical [y/n]? \")\n",
    "    if identicalPlates == 'y':\n",
    "        numplates = int(input('How many identical plates are there [int]? '))\n",
    "        if not isinstance(numplates, int):\n",
    "            raise Warning(\"Invalid response. Answer must be an integer. Exiting...\")\n",
    "            sys.exit()\n",
    "    elif identicalPlates == 'n':\n",
    "        pass\n",
    "    else:\n",
    "        raise Warning(\"Invalid response. Answer must be 'y' or 'n'. Exiting...\")\n",
    "        sys.exit()\n",
    "    \n",
    "    files2_AnalyzedAllParameters = []\n",
    "\n",
    "    for plateFolder in plateFolders:\n",
    "        if 'platemap' in plateFolder:\t# Ignore platemap file(s)\n",
    "            continue\n",
    "        else:\n",
    "            platePath = experimentPath + '\\\\' + plateFolder\n",
    "        # Create lists of .xlsx filenames to be merged\n",
    "        files2_AnalyzedAllParameters.append(platePath + '\\\\' + '2_AnalyzedAllParameters_' + plateFolder + '.xlsx')\n",
    "    \n",
    "    # Open .xlsx file(s) and fix rep numbers for concatenation (e.g. Reps 1-6 on 2 plates become Reps 1-12 in compiled file)\n",
    "    if identicalPlates == 'y':\n",
    "        for i in range(1,len(files2_AnalyzedAllParameters)):\n",
    "            wb = xl.load_workbook(files2_AnalyzedAllParameters[i])\n",
    "            sheet = wb.worksheets[0]\n",
    "            repCol = 0\n",
    "            for column in range(1,sheet.max_column+1):\n",
    "                if sheet.cell(row = 1, column = column).value == 'Rep':\n",
    "                    repCol = column\n",
    "            maxRep = 0\n",
    "            for row in range(2, sheet.max_row+1):\n",
    "                if sheet.cell(row = row, column = repCol).value > maxRep:\n",
    "                    maxRep = sheet.cell(row = row, column = repCol).value\n",
    "            for row in range(2, sheet.max_row+1):\n",
    "                sheet.cell(row = row, column = repCol).value += (maxRep * i)\n",
    "            wb.save(compiledPath + '\\\\2_AnalyzedAllParameters_' + plateFolders[i] + '_RepsCorrected.xlsx')\n",
    "            files2_AnalyzedAllParameters[i] = compiledPath + '\\\\2_AnalyzedAllParameters_' + plateFolders[i] + '_RepsCorrected.xlsx'\n",
    "    \n",
    "    # Read .xlsx files as pandas dataframes, then append to lists for concatenation\n",
    "    list2_AnalyzedAllParameters = []\n",
    "\n",
    "    for file in files2_AnalyzedAllParameters:\n",
    "        list2_AnalyzedAllParameters.append(pd.read_excel(file))\n",
    "    \n",
    "    # Concatenate dataframes\n",
    "    df2 = pd.concat(list2_AnalyzedAllParameters)\n",
    "\n",
    "    # Export to .xlsx\n",
    "    df2.to_excel(compiledPath + \"\\\\2_AnalyzedAllParameters_Compiled.xlsx\", index=False)\n",
    "    print(\"Excel files merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mergePlateOutputFiles(experimentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normZscore(experimentPath):\n",
    "    # List plate subfolders\n",
    "    plateFolders = os.listdir(experimentPath)\n",
    "    plateFolders = [x for x in plateFolders if '.csv' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.raw' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.txt' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.xlsx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.docx' not in x]\n",
    "    \n",
    "    # Loop through each plate folder\n",
    "    for plateFolder in plateFolders:\n",
    "        if 'platemap' in plateFolder:\t# Ignore platemap file(s)\n",
    "            continue\n",
    "        else:\n",
    "            platePath = experimentPath + '\\\\' + plateFolder\t\n",
    "\n",
    "        wb = xl.load_workbook(platePath + '\\\\' + '2_AnalyzedAllParameters_' + plateFolder + '.xlsx') \t\t# Load workbook\n",
    "        sheets = wb.sheetnames\t\t\t\t\t\t\t# Create list of all worksheets\n",
    "\n",
    "        for page in range(0, len(sheets)):\t \t\t\t# Loop through sheets (days)\n",
    "            sheet = wb.worksheets[page]\n",
    "            for col in range(5,sheet.max_column+1):\n",
    "                colvals = []\n",
    "                for row in range(2,sheet.max_row+1):\n",
    "                    if sheet.cell(row = row, column = col).value == None:\n",
    "                        pass\n",
    "                    elif type(sheet.cell(row = row, column = col).value) == str:\n",
    "                        pass\t\n",
    "                    else:\n",
    "                        colvals.append(sheet.cell(row = row, column = col).value)\n",
    "                col_mean = np.mean(colvals)\n",
    "                col_std = np.std(colvals)\n",
    "                for row in range(2,sheet.max_row+1):\n",
    "                    if sheet.cell(row = row, column = col).value == None:\n",
    "                        pass\n",
    "                    elif type(sheet.cell(row = row, column = col).value) == str:\n",
    "                        pass\n",
    "                    else:\n",
    "                        sheet.cell(row = row, column = col).value = ((sheet.cell(row = row, column = col).value - col_mean) / col_std)\n",
    "\n",
    "        wb.save(platePath + '\\\\' + '3_Zscore_' + plateFolder + '.xlsx')\n",
    "        print('Z-score Excel file exported for ' + plateFolder + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "normZscore(experimentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAS(experimentPath):\n",
    "    # List plate subfolders\n",
    "    plateFolders = os.listdir(experimentPath)\n",
    "    plateFolders = [x for x in plateFolders if '.csv' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.raw' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.txt' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.xlsx' not in x]\n",
    "    plateFolders = [x for x in plateFolders if '.docx' not in x]\n",
    "    \n",
    "    # Loop through each plate folder\n",
    "    for plateFolder in plateFolders:\n",
    "        if 'platemap' in plateFolder:\t# Ignore platemap file(s)\n",
    "            continue\n",
    "        else:\n",
    "            platePath = experimentPath + '\\\\' + plateFolder\n",
    "\n",
    "        wb = xl.load_workbook(platePath + '\\\\' + '3_Zscore_' + plateFolder + '.xlsx') \t\t# Load workbook\n",
    "        sheets = wb.sheetnames   # Create list of all worksheets\n",
    "        sheet = wb.worksheets[0]\n",
    "\n",
    "        for col in range(1,sheet.max_column+1):\n",
    "            if sheet.cell(row = 1, column = col).value == 'Mean Firing Rate (Hz)':\n",
    "                meanFiringRate = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'ISI Coefficient of Variation':\n",
    "                ISIcoeffVar = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'ISI Coefficient of Variation - Avg':\n",
    "                ISIcoeffVar = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Number of Bursting Electrodes':\n",
    "                numBurstingElecs = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Burst Duration - Avg (s)':\n",
    "                burstDuration = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Number of Spikes per Burst - Avg':\n",
    "                numSpikesPerBurst = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Mean ISI within Burst - Avg':\n",
    "                meanISIwithinBurst = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Median ISI within Burst - Avg':\n",
    "                medianISIwithinBurst = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Inter-Burst Interval - Avg (s)':\n",
    "                IBI = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Burst Frequency - Avg (Hz)':\n",
    "                burstFreq = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Normalized Duration IQR - Avg':\n",
    "                normDurationIQR = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'IBI Coefficient of Variation - Avg':\n",
    "                IBIcoeffVar = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Burst Percentage - Avg':\n",
    "                burstPercentage = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Network Burst Frequency (Hz)':\n",
    "                networkBurstFreq = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Network Burst Duration - Avg (sec)':\n",
    "                networkBurstDuration = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Number of Spikes per Network Burst - Avg':\n",
    "                numSpikesPerNetworkBurst = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Number of Elecs Participating in Burst - Avg':\n",
    "                numElecsParticipatingInBurst = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Number of Spikes per Network Burst per Channel - Avg':\n",
    "                numSpikesPerNetworkBurstPerChannel = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Network Burst Percentage':\n",
    "                networkBurstPercentage = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Network IBI Coefficient of Variation':\n",
    "                networkIBIcoeffVar = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Network Normalized Duration IQR':\n",
    "                networkNormDurationIQR = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Area Under Normalized Cross-Correlation':\n",
    "                areaUnderNormalizedCrossCorrelation = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Area Under Cross-Correlation':\n",
    "                areaUnderCrossCorrelation = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Width at Half Height of Normalized Cross-Correlation':\n",
    "                halfWidthNormalizedCrossCorrelation = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Width at Half Height of Cross-Correlation':\n",
    "                halfWidthCrossCorrelation = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Half Width at Half Height of Normalized Cross-Correlation':\n",
    "                halfWidthNormalizedCrossCorrelation = col\n",
    "                continue                \n",
    "            elif sheet.cell(row = 1, column = col).value == 'Half Width at Half Height of Cross-Correlation':\n",
    "                halfWidthCrossCorrelation = col\n",
    "                continue\n",
    "            elif sheet.cell(row = 1, column = col).value == 'Synchrony Index':\n",
    "                syncIndex = col\n",
    "                continue                \n",
    "\n",
    "        for page in range(0, len(sheets)):   # Loop through sheets (days)\n",
    "            sheet = wb.worksheets[page]\n",
    "            maxCol = sheet.max_column\n",
    "            sheet.cell(row = 1, column = maxCol+1).value = \"NAS\"\n",
    "            for row in range(2,sheet.max_row+1):\n",
    "                index_score = \\\n",
    "                (sheet.cell(row = row, column = meanFiringRate).value * 0.78723) + \\\n",
    "                (sheet.cell(row = row, column = ISIcoeffVar).value * 0.87546) + \\\n",
    "                (sheet.cell(row = row, column = numBurstingElecs).value * 0.92474) + \\\n",
    "                (sheet.cell(row = row, column = burstDuration).value * 0.73062) + \\\n",
    "                (sheet.cell(row = row, column = numSpikesPerBurst).value * 0.92763) + \\\n",
    "                (sheet.cell(row = row, column = meanISIwithinBurst).value * 0.02926) + \\\n",
    "                (sheet.cell(row = row, column = medianISIwithinBurst).value * -0.05205) + \\\n",
    "                (sheet.cell(row = row, column = IBI).value * -0.27591) + \\\n",
    "                (sheet.cell(row = row, column = burstFreq).value * 0.59294) + \\\n",
    "                (sheet.cell(row = row, column = normDurationIQR).value * 0.70740) + \\\n",
    "                (sheet.cell(row = row, column = IBIcoeffVar).value * 0.64845) + \\\n",
    "                (sheet.cell(row = row, column = burstPercentage).value * 0.93895) + \\\n",
    "                (sheet.cell(row = row, column = networkBurstFreq).value * 0.50654) + \\\n",
    "                (sheet.cell(row = row, column = networkBurstDuration).value * 0.49079) + \\\n",
    "                (sheet.cell(row = row, column = numSpikesPerNetworkBurst).value * 0.90668) + \\\n",
    "                (sheet.cell(row = row, column = numElecsParticipatingInBurst).value * 0.86659) + \\\n",
    "                (sheet.cell(row = row, column = numSpikesPerNetworkBurstPerChannel).value * 0.91682) + \\\n",
    "                (sheet.cell(row = row, column = networkBurstPercentage).value * 0.93034) + \\\n",
    "                (sheet.cell(row = row, column = networkIBIcoeffVar).value * 0.73943) + \\\n",
    "                (sheet.cell(row = row, column = networkNormDurationIQR).value * 0.61389) + \\\n",
    "                (sheet.cell(row = row, column = areaUnderNormalizedCrossCorrelation).value * 0.86675) + \\\n",
    "                (sheet.cell(row = row, column = areaUnderCrossCorrelation).value * 0.60665) + \\\n",
    "                (sheet.cell(row = row, column = halfWidthNormalizedCrossCorrelation).value * 0.17513) + \\\n",
    "                (sheet.cell(row = row, column = halfWidthCrossCorrelation).value * 0.23308) + \\\n",
    "                (sheet.cell(row = row, column = syncIndex).value * 0.91299)\n",
    "                sheet.cell(row = row, column = maxCol+1).value = index_score\n",
    "\n",
    "        # Compile NAS in GraphPad format\n",
    "        # Create sheet with only Rep, Group, Day, Index Score columns\n",
    "        wb.create_sheet('NAS')\n",
    "        isSheet = wb['NAS']\n",
    "        for i in range(1,sheet.max_row+1):\n",
    "            for j in [1,2,3,4]:\n",
    "                isSheet.cell(row = i, column = j).value = sheet.cell(row = i, column = j).value\n",
    "            isSheet.cell(row = i, column = 5).value = sheet.cell(row = i, column = maxCol+1).value\n",
    "\n",
    "        # Remove outliers\n",
    "        indexScoreData = isSheet.values\n",
    "        indexScoreDataHeaders = next(indexScoreData)[0:]\n",
    "        isDF = pd.DataFrame(indexScoreData, columns=indexScoreDataHeaders) # Convert to dataframe\n",
    "        isDF['NAS (z)'] = stats.zscore(isDF['NAS']) # Z-score NAS column\n",
    "        isDFz = isDF['NAS (z)'].tolist()\n",
    "        isSheet.cell(row = 1, column = 6).value = 'NAS (z)'\n",
    "        for i in range(2, len(isDFz)+2):\n",
    "            isSheet.cell(row = i, column = 6).value = isDFz[i-2]\n",
    "\n",
    "        # Scale to 0-1\n",
    "        isSheet.cell(row = 1, column = 7).value = 'NAS (scaled)'\n",
    "        isVals = [isSheet.cell(row = x, column = 5).value for x in range(2,isSheet.max_row+1) if isSheet.cell(row = x, column = 6).value < 3 and isSheet.cell(row = x, column = 6).value > -3]\n",
    "        minISval = min(isVals)\n",
    "        maxISval = max(isVals)\n",
    "        for i in range(2,isSheet.max_row+1):\n",
    "            if isSheet.cell(row = i, column = 6).value > 3 or isSheet.cell(row = i, column = 6).value < -3:\n",
    "                isSheet.cell(row = i, column = 7).value = 'Outlier'\n",
    "            else:\n",
    "                isSheet.cell(row = i, column = 7).value = (isSheet.cell(row = i, column = 5).value - minISval)/(maxISval - minISval)\n",
    "\n",
    "        # Convert to dataFrame\n",
    "        indexScoreData = isSheet.values\n",
    "        indexScoreDataHeaders = next(indexScoreData)[0:]\n",
    "        dfIndexScore = pd.DataFrame(indexScoreData, columns=indexScoreDataHeaders)\n",
    "\n",
    "        wb.create_sheet('NAS scaled - GraphPad format') # Create sheet for GraphPad format\n",
    "        gpSheet = wb['NAS scaled - GraphPad format']\n",
    "        dfIndexScore.sort_values(by=['Group', 'Day', 'Rep'], inplace=True) # Sort index score dataframe\n",
    "        repList = []\n",
    "        groupList = []\n",
    "        dayList = []\n",
    "        for index, row in dfIndexScore.iterrows(): # Loop through rows of sorted dataframe\n",
    "            if row[0] not in repList: # Create list of reps\n",
    "                repList.append(row[0])\n",
    "            if row[1] not in groupList: # Create list of groups\n",
    "                groupList.append(row[1])\n",
    "            if row[2] not in dayList: # Create list of days\n",
    "                dayList.append(row[2])\n",
    "        \n",
    "        # Fill in GraphPad format sheet\n",
    "        gpSheet.cell(row = 1, column = 1).value = 'DIV'\n",
    "        for i in range(2,len(dayList)+2):\n",
    "            gpSheet.cell(row = i, column = 1).value = dayList[i-2]\n",
    "        groupCount, dayCount, repCount = 1, 1, 1\n",
    "        for index, row in dfIndexScore.iterrows():\n",
    "            gpSheet.cell(row = 1, column = ((groupCount-1)*len(repList)) + repCount + 1).value = row[1]\n",
    "            if groupCount < len(groupList)+1:\n",
    "                if dayCount < len(dayList):\n",
    "                    if repCount < len(repList):\n",
    "                        gpSheet.cell(row = dayCount+1, column = ((groupCount-1)*len(repList)) + repCount + 1).value = row[6]\n",
    "                        repCount += 1\n",
    "                    elif repCount == len(repList):\n",
    "                        gpSheet.cell(row = dayCount+1, column = ((groupCount-1)*len(repList)) + repCount + 1).value = row[6]\n",
    "                        dayCount += 1 # Add to day counter\n",
    "                        repCount = 1 # Reset rep counter\n",
    "                elif dayCount == len(dayList):\n",
    "                    if repCount < len(repList):\n",
    "                        gpSheet.cell(row = dayCount+1, column = ((groupCount-1)*len(repList)) + repCount + 1).value = row[6]\n",
    "                        repCount += 1\n",
    "                    elif repCount == len(repList):\n",
    "                        gpSheet.cell(row = dayCount+1, column = ((groupCount-1)*len(repList)) + repCount + 1).value = row[6]\n",
    "                        gpSheet.merge_cells(start_row=1, start_column=((groupCount-1)*len(repList) + 2), \\\n",
    "                        end_row=1, end_column=((groupCount-1)*len(repList) + 1 + len(repList))) # ...Merge group header cells before moving to next group\n",
    "                        groupCount += 1 # Add to group counter\n",
    "                        dayCount = 1 # Reset day counter\n",
    "                        repCount = 1 # Reset rep counter\n",
    "            elif groupCount == len(groupList)+1:\n",
    "                break\n",
    "\n",
    "        wb.save(platePath + '\\\\' + '4_NAS_' + plateFolder + '.xlsx')\n",
    "    print('NAS Excel files exported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAS(experimentPath)\n",
    "print('Analysis complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
